# Hand Boundary POC

Real-time hand tracking system with **TinyUNet ONNX segmentation** and SAFE/WARNING/DANGER state machine.

> âš ï¸ **IMPORTANT**: This system uses **ONLY** the TinyUNet ONNX model for segmentation.
> **No fallback modes** (HSV, skin-color, motion) are available.
> You **must train the model** before running the application.

![Python 3.8+](https://img.shields.io/badge/Python-3.8+-blue.svg)
![OpenCV](https://img.shields.io/badge/OpenCV-4.8+-green.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)
![ONNXRuntime](https://img.shields.io/badge/ONNX-1.15+-purple.svg)

## Features

- **Real-time webcam tracking** of hand and fingertip
- **TinyUNet CNN** for binary hand mask prediction (160Ã—160 input)
- **Classical CV** contour + convex hull fingertip detection
- **Distance-based state machine** with hysteresis:
  - ðŸŸ¢ **SAFE**: distance > 80px
  - ðŸŸ¡ **WARNING**: 10px < distance â‰¤ 80px
  - ðŸ”´ **DANGER**: distance â‰¤ 10px + "DANGER DANGER" overlay
- **â‰¥8 FPS** CPU-only inference
- **No MediaPipe/OpenPose/Cloud APIs**
- **No fallback segmentation** â€” model must be trained

## Quick Start

### 1. Install Dependencies

```bash
cd hand_boundary_poc
pip install -r requirements.txt
```

### 2. Prepare Dataset

```bash
python train/prepare_dataset.py --output_dir ./data --num_synthetic 500
```

### 3. Train the Model

```bash
python train/train_unet.py --data_dir ./data/synthetic --epochs 30
```

### 4. Export to ONNX

```bash
python train/export_onnx.py --checkpoint ./checkpoints/best_model.pth --output ./models/handseg.onnx
```

### 5. Run the Application

```bash
python src/main.py
```

**Controls:**
- Press `Q` to quit

## Architecture

### TinyUNet Model

```
Input: 160Ã—160Ã—3 RGB

Encoder:
â”œâ”€â”€ DoubleConv: 3 â†’ 32 channels (160Ã—160)
â”œâ”€â”€ Down + DoubleConv: 32 â†’ 64 channels (80Ã—80)
â””â”€â”€ Down + DoubleConv: 64 â†’ 128 channels (40Ã—40)

Decoder:
â”œâ”€â”€ Up + DoubleConv: 128 â†’ 64 channels (80Ã—80)
â”œâ”€â”€ Up + DoubleConv: 64 â†’ 32 channels (160Ã—160)
â””â”€â”€ 1Ã—1 Conv: 32 â†’ 1 channel (mask output)

Output: 160Ã—160Ã—1 binary mask
```

### Processing Pipeline

```
Camera Frame
     â†“
TinyUNet ONNX Model
     â†“
Binary Mask â†’ Morphological Cleanup
     â†“
Find Contour â†’ Convex Hull â†’ Fingertip
     â†“
Distance to Rectangle
     â†“
State Machine (SAFE/WARNING/DANGER)
     â†“
Draw Overlays â†’ Display
```

## Project Structure

```
hand_boundary_poc/
â”œâ”€â”€ README.md                         # This file
â”œâ”€â”€ DEVPLAN.md                        # Development plan
â”œâ”€â”€ requirements.txt                  # Dependencies
â”œâ”€â”€ models/
â”‚   â””â”€â”€ handseg.onnx                  # Trained ONNX model
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ prepare_dataset.py            # Dataset preparation
â”‚   â”œâ”€â”€ train_unet.py                 # Training script
â”‚   â””â”€â”€ export_onnx.py                # ONNX export
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                       # Main application
â”‚   â”œâ”€â”€ config.py                     # Configuration
â”‚   â”œâ”€â”€ camera/
â”‚   â”‚   â””â”€â”€ capture.py                # Webcam wrapper
â”‚   â”œâ”€â”€ vision/
â”‚   â”‚   â”œâ”€â”€ segmentation_model.py     # ONNX inference (NO FALLBACK)
â”‚   â”‚   â””â”€â”€ hand_analyzer.py          # Contour/hull/fingertip
â”‚   â”œâ”€â”€ interaction/
â”‚   â”‚   â”œâ”€â”€ virtual_object.py         # Rectangle boundary
â”‚   â”‚   â””â”€â”€ state_machine.py          # State logic
â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â””â”€â”€ overlay.py                # UI rendering
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ timing.py                 # FPS counter
â”‚       â””â”€â”€ image_utils.py            # Image utilities
â””â”€â”€ tests/
    â”œâ”€â”€ test_segmentation_model.py
    â”œâ”€â”€ test_hand_analyzer.py
    â””â”€â”€ test_state_machine.py
```

## Configuration

Edit `src/config.py` to adjust:

```python
# Frame settings
FRAME_WIDTH = 640
FRAME_HEIGHT = 480

# Model
MODEL_INPUT_SZ = 160
MODEL_PATH = "models/handseg.onnx"

# Distance thresholds
DIST_DANGER = 10.0     # pixels
DIST_WARNING = 80.0    # pixels
HYSTERESIS_MARGIN = 15.0
SMOOTHING_BUFFER_SIZE = 5

# Virtual rectangle position
VBOX_X = 400
VBOX_Y = 150
VBOX_W = 200
VBOX_H = 200
```

## Testing

```bash
# Run all tests
python -m pytest tests/ -v

# Run specific test
python -m pytest tests/test_state_machine.py -v
```

## Requirements

### Runtime
- Python 3.8+
- OpenCV 4.8+
- NumPy 1.24+
- ONNXRuntime 1.15+
- Webcam

### Training
- PyTorch 2.0+
- torchvision 0.15+
- albumentations 1.3+

## Performance

| Metric | Target | Typical |
|--------|--------|---------|
| FPS | â‰¥ 8 | 15-30 |
| Model Size | < 5MB | ~2MB |
| Latency | < 125ms | 33-66ms |

## Troubleshooting

### Model not found error
```
ERROR: ONNX model not found!
```
**Solution:** Train the model first using the steps in Quick Start.

### Camera not detected
```bash
python -c "import cv2; print(cv2.VideoCapture(0).isOpened())"
```

### Low FPS
1. Reduce `MODEL_INPUT_SZ` to 128 in `config.py`
2. Ensure no other applications using webcam
3. Check CPU usage

## Constraints (Recruiter Requirements)

This project strictly adheres to the following constraints:

- âœ… **CPU-only** inference
- âœ… **TinyUNet ONNX** model only
- âœ… **No MediaPipe/OpenPose**
- âœ… **No cloud APIs**
- âŒ **No HSV/skin-color segmentation**
- âŒ **No motion-based segmentation**
- âŒ **No fallback modes**

## License

MIT License

## Acknowledgments

- TinyUNet architecture inspired by U-Net (Ronneberger et al., 2015)
